{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "69e4d7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello GPT\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello GPT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "91cdfa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"../data/sherlock-holmes.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "129fe47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the dataset: 3863958\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of the dataset: {len(text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "14c35c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               A STUDY IN SCARLET\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                Table of contents\n",
      "\n",
      "         Part I\n",
      "        Mr. Sherlock Holmes\n",
      "        The Science Of Deduction\n",
      "        The Lauriston Garden Mystery\n",
      "        What John Rance Had To Tell\n",
      "        Our Advertisement Brings A Visitor\n",
      "        Tobias Gregson Shows What He Can Do\n",
      "        Light In The Darkness\n",
      "\n",
      "         Part II\n",
      "        On The Great Alkali Plain\n",
      "        The Flower Of Utah\n",
      "        John Ferrier Talks With The Prophet\n",
      "        A Flight For Life\n",
      "        The Avenging Angels\n",
      "        A Continuation Of The Reminiscences Of John Watson, M.D.\n",
      "        The Conclusion\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                      PART I\n",
      "\n",
      "                   (Being a reprint from the reminiscences of\n",
      "                              John H. Watson, M.D.,\n",
      "                      late of the Army Medical Department.)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "          CHAPTER I\n",
      "          Mr. Sherlock Holmes\n",
      "\n",
      "\n",
      "     In the year 1878 I took my degree of Doctor of Medicine of th\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d913680b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Remove multiple contiguous blank lines\"\"\"\n",
    "flag_blank_line = False\n",
    "processed_text = []\n",
    "\n",
    "for line in text.split(\"\\n\"):\n",
    "    if not line.strip():\n",
    "        if not flag_blank_line:\n",
    "            processed_text.append('')\n",
    "            flag_blank_line = True\n",
    "        else:\n",
    "            continue\n",
    "    else:\n",
    "        flag_blank_line = False\n",
    "        processed_text.append(line.strip())\n",
    "        \n",
    "\n",
    "processed_text = '\\n'.join(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "98c88603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A STUDY IN SCARLET\n",
      "\n",
      "Table of contents\n",
      "\n",
      "Part I\n",
      "Mr. Sherlock Holmes\n",
      "The Science Of Deduction\n",
      "The Lauriston Garden Mystery\n",
      "What John Rance Had To Tell\n",
      "Our Advertisement Brings A Visitor\n",
      "Tobias Gregson Shows What He Can Do\n",
      "Light In The Darkness\n",
      "\n",
      "Part II\n",
      "On The Great Alkali Plain\n",
      "The Flower Of Utah\n",
      "John Ferrier Talks With The Prophet\n",
      "A Flight For Life\n",
      "The Avenging Angels\n",
      "A Continuation Of The Reminiscences Of John Watson, M.D.\n",
      "The Conclusion\n",
      "\n",
      "PART I\n",
      "\n",
      "(Being a reprint from the reminiscences of\n",
      "John H. Watson, M.D.,\n",
      "late of the Army Medical Department.)\n",
      "\n",
      "CHAPTER I\n",
      "Mr. Sherlock Holmes\n",
      "\n",
      "In the year 1878 I took my degree of Doctor of Medicine of the\n",
      "University of London, and proceeded to Netley to go through the\n",
      "course prescribed for surgeons in the army. Having completed my\n",
      "studies there, I was duly attached to the Fifth Northumberland\n",
      "Fusiliers as Assistant Surgeon. The regiment was stationed in India\n",
      "at the time, and before I could join it, the second Afghan war had\n",
      "broken out. On landing at \n"
     ]
    }
   ],
   "source": [
    "print(processed_text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "aea9b44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !\"&'()*,-.0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]`abcdefghijklmnopqrstuvwxyz£°½ßàâèéêîñôöûü’\n"
     ]
    }
   ],
   "source": [
    "unique_characters = sorted(list(set(processed_text)))\n",
    "vocab_size = len(unique_characters)\n",
    "print(''.join(unique_characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "2cebb1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vocabulary Size: 96\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nVocabulary Size: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4246f3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Tokenizing characters\"\"\"\n",
    "character_integer_mapping = { char:index for index,char in enumerate(unique_characters) }\n",
    "integer_character_mapping = { index:char for index,char in enumerate(unique_characters) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ae1aa2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(string):\n",
    "    \"\"\"\n",
    "    Encode string\n",
    "        Input: list of characters\n",
    "        Output: list of mapped integers\n",
    "    \"\"\"\n",
    "    output = []\n",
    "    for character in string:\n",
    "        output.append(character_integer_mapping[character])\n",
    "    \n",
    "    return output        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c4a82a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[32, 62, 1, 73, 61, 58, 71, 58]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode(\"Hi there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5d6d7786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(integers):\n",
    "    \"\"\"\n",
    "    Decode string\n",
    "        Input: list of integers\n",
    "        Output: corresponding mapped string\n",
    "    \"\"\"\n",
    "    output = \"\"\n",
    "    for integer in integers:\n",
    "        output += integer_character_mapping[integer]\n",
    "    \n",
    "    return output        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3544c641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi there'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode([32, 62, 1, 73, 61, 58, 71, 58])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "6c0c89e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Encode entire dataset -> store in a tensor\"\"\"\n",
    "import torch\n",
    "\n",
    "encoded_text = encode(processed_text)\n",
    "data = torch.tensor(encoded_text, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a59e1494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data tensor shape: torch.Size([3557691])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data tensor shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7af0953e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([25,  1, 43, 44, 45, 28, 49,  1, 33, 38,  1, 43, 27, 25, 42, 36, 29, 44,\n",
      "         0,  0, 44, 54, 55, 65, 58,  1, 68, 59,  1, 56, 68, 67, 73, 58, 67, 73,\n",
      "        72,  0,  0, 40, 54, 71, 73,  1, 33,  0, 37, 71, 11,  1, 43, 61, 58, 71,\n",
      "        65, 68, 56, 64,  1, 32, 68, 65, 66, 58, 72,  0, 44, 61, 58,  1, 43, 56,\n",
      "        62, 58, 67, 56, 58,  1, 39, 59,  1, 28, 58, 57, 74, 56, 73, 62, 68, 67,\n",
      "         0, 44, 61, 58,  1, 36, 54, 74, 71, 62])\n"
     ]
    }
   ],
   "source": [
    "print(data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "3c3aaf60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape: torch.Size([3201921])\n",
      "Validation dataset shape: torch.Size([355770])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Train-Test Split\"\"\"\n",
    "\n",
    "n = int(0.9 * len(data))\n",
    "\n",
    "train_data = data[:n]\n",
    "validation_data = data[n:]\n",
    "\n",
    "print(f\"Train dataset shape: {train_data.shape}\")\n",
    "print(f\"Validation dataset shape: {validation_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "33acb7d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([25,  1, 43, 44, 45, 28, 49,  1, 33])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 4\n",
    "context_length = 8\n",
    "train_data[:context_length + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "eb965720",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split: str):\n",
    "    \"\"\"Generate a batch of data [batch_size, context_length]\"\"\"\n",
    "    data = train_data if split == \"train\" else validation_data\n",
    "    indices = torch.randint(len(data) - context_length, (batch_size,))\n",
    "    \n",
    "    x = torch.stack([data[index:index+context_length] for index in indices])\n",
    "    y = torch.stack([data[index+1:index+context_length+1] for index in indices])\n",
    "    \n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "133ec784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: torch.Size([4, 8])\n",
      "tensor([[54, 65,  1, 62, 72,  1, 73, 61],\n",
      "        [57,  1, 73, 61, 58,  1, 56, 61],\n",
      "        [72, 62, 71, 58, 57,  0, 73, 68],\n",
      "        [74, 73,  1, 54, 60, 54, 62, 67]])\n",
      "\n",
      "Targets: torch.Size([4, 8])\n",
      "tensor([[65,  1, 62, 72,  1, 73, 61, 54],\n",
      "        [ 1, 73, 61, 58,  1, 56, 61, 68],\n",
      "        [62, 71, 58, 57,  0, 73, 68,  1],\n",
      "        [73,  1, 54, 60, 54, 62, 67, 11]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xb, yb = get_batch(\"train\")\n",
    "print(f\"Inputs: {xb.shape}\\n{xb}\\n\")\n",
    "print(f\"Targets: {yb.shape}\\n{yb}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "304c4db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Lookup table for logits\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "        \n",
    "    def forward(self, index, targets=None):\n",
    "        # index, targets are of the size (B,T)\n",
    "        # logits are of the size (B,T,C)\n",
    "        logits = self.token_embedding_table(index)\n",
    "        \n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            # reshape tensors\n",
    "            logits_flat = logits.view(B*T, C)\n",
    "            targets_flat = targets.view(B*T)\n",
    "            \n",
    "            loss = nn.CrossEntropyLoss()(logits_flat, targets_flat)\n",
    "        \n",
    "        return logits, loss      \n",
    "    \n",
    "    def generate(self, index, max_tokens):\n",
    "        \"\"\"\n",
    "        For each input index:\n",
    "            - forward pass -> logits, loss\n",
    "            - focus only on the last time step\n",
    "            - compute probabilities\n",
    "            - get next index\n",
    "            - concat this new index to the original tensor, this becomes the new input\n",
    "            \n",
    "        index - [B,T]\n",
    "        max_tokens - int            \n",
    "        \"\"\"\n",
    "        for _ in range(max_tokens):\n",
    "            logits, loss = self(index) # [B,T,C]\n",
    "            logits = logits[:,-1,:] # [B,C]\n",
    "            probabilities = nn.Softmax(dim=-1)(logits) # [B,C]\n",
    "            \n",
    "            # sample an index from the distribution\n",
    "            # this avoids picking only the top choice, introduces variability of output\n",
    "            next_index = torch.multinomial(probabilities, num_samples=1)\n",
    "            index = torch.cat((index, next_index), dim=1) # [B,T+1]\n",
    "            \n",
    "        return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "56ba3277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "jècß!ß'459W.2ñböüb-fû.`éSSs(hJx\n",
      "Füf;h9prq9)Voè,npfu1-0j’Eo2Eâlkê[z\"j)6ZeûL:à,üSxCéqRQ9ßDèp.ñpHDqg]b\"\n"
     ]
    }
   ],
   "source": [
    "model = BigramLanguageModel(vocab_size)\n",
    "output, loss = model(xb,yb)\n",
    "\n",
    "test_output = model.generate(torch.zeros((1,1), dtype=torch.long), max_tokens=100)[0].tolist()\n",
    "print(decode(test_output))\n",
    "\n",
    "# print(f\"Output shape: {output.shape}\")\n",
    "# print(f\"Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "39169c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "# model = BigramLanguageModel(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "1117940f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5403785705566406\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "for steps in range(100):\n",
    "    # sample a batch\n",
    "    xb, yb = get_batch(\"train\")\n",
    "    logits, loss = model(xb,yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # if steps % 1000 == 0:\n",
    "print(loss.item())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "675dd000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output string: \n",
      "\n",
      "L. bed;D\"INe tu&°Cha&(-C( wñospul ithoueean wabo\n",
      "\n",
      "\n",
      "\"Y7is Ylincl&ßd;ahaxush o inWe7î*Q7-p;ZHQBSqee\n",
      "\"Dinis en meth lw!SZèAm?G°me waie h s: be con Twharin\n",
      "\n",
      "t ssesaHbaber. ha in tofo\n",
      "\n",
      "stobed ath\n",
      "te T°;ad isere whay ubes p n tbucr m wa almjèfofirwhinwhavern an d\n",
      "fabltab’G73've t;’Iste co orercñ2w2ben r y.9MipreLUHd veth w emy\n",
      "Aûkim imZ)*U2£Ffo tinvifrthves I Thtd tu llid ofrve,At\n",
      "s ce thad\n",
      "E£hans frd omporzàq?\"caVXkf \"Jarintht er\" whe ce s sacalinn If mm.R8Z[!½'ôfithe as anlivinceporend usmas, ISiol\n"
     ]
    }
   ],
   "source": [
    "output = model.generate(torch.zeros((1,1), dtype=torch.long), max_tokens=500)[0].tolist()\n",
    "\n",
    "print(f\"Output string: {decode(output)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3051cdf",
   "metadata": {},
   "source": [
    "**Self Attention**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "e4872152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 2])\n"
     ]
    }
   ],
   "source": [
    "B, T, C = 4, 8, 2\n",
    "x = torch.randn((B,T,C))\n",
    "\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4120dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Causal Bag-of-Words\"\"\"\n",
    "\n",
    "# version 1\n",
    "xbow = torch.zeros((B,T,C))\n",
    "\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, :t+1, :] # [t,C]\n",
    "        xbow[b,t, :] = torch.mean(xprev, 0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "d68584d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This results in summation\n",
      "a:\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "\n",
      "b:\n",
      "tensor([[8., 3., 5.],\n",
      "        [7., 2., 4.],\n",
      "        [6., 3., 6.]])\n",
      "\n",
      "c:\n",
      "tensor([[21.,  8., 15.],\n",
      "        [21.,  8., 15.],\n",
      "        [21.,  8., 15.]])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Matrix multiplication trick for implementing causal attention\"\"\"\n",
    "\n",
    "torch.manual_seed(40)\n",
    "a = torch.ones((3,3))\n",
    "b = torch.randint(0, 10, (3,3), dtype=torch.float)\n",
    "c = a @ b\n",
    "\n",
    "print(\"This results in summation\")\n",
    "print(f\"a:\\n{a}\")\n",
    "print(f\"\\nb:\\n{b}\")\n",
    "print(f\"\\nc:\\n{c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "8b556599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This results in summation\n",
      "a:\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "\n",
      "b:\n",
      "tensor([[8., 3., 5.],\n",
      "        [7., 2., 4.],\n",
      "        [6., 3., 6.]])\n",
      "\n",
      "c:\n",
      "tensor([[8.0000, 3.0000, 5.0000],\n",
      "        [7.5000, 2.5000, 4.5000],\n",
      "        [7.0000, 2.6667, 5.0000]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(40)\n",
    "\n",
    "# use lower triangular matrix for causal masking\n",
    "a = torch.tril(torch.ones((3,3)))\n",
    "a = a / torch.sum(a, 1, keepdim=True)\n",
    "b = torch.randint(0, 10, (3,3), dtype=torch.float)\n",
    "c = a @ b\n",
    "\n",
    "print(\"This results in summation\")\n",
    "print(f\"a:\\n{a}\")\n",
    "print(f\"\\nb:\\n{b}\")\n",
    "print(f\"\\nc:\\n{c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1332a2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 2\n",
    "weights = torch.tril(torch.ones(T,T))\n",
    "weights = weights / torch.sum(weights, 1, keepdim=True)\n",
    "xbow2 = weights @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "00f834eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "ca774563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(xbow, xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "6291f8f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.2075, -0.6231],\n",
       "         [ 0.0937,  0.4413],\n",
       "         [ 0.1438, -0.0314],\n",
       "         [ 0.0358,  0.0413],\n",
       "         [ 0.1443,  0.1019],\n",
       "         [ 0.2577,  0.3573],\n",
       "         [ 0.1840,  0.0644],\n",
       "         [ 0.1088,  0.0769]]),\n",
       " tensor([[ 0.2075, -0.6231],\n",
       "         [ 0.0937,  0.4413],\n",
       "         [ 0.1438, -0.0314],\n",
       "         [ 0.0358,  0.0413],\n",
       "         [ 0.1443,  0.1019],\n",
       "         [ 0.2577,  0.3573],\n",
       "         [ 0.1840,  0.0644],\n",
       "         [ 0.1088,  0.0769]]))"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# identical\n",
    "xbow[2], xbow2[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "cbd47bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 3\n",
    "# using softmax\n",
    "\n",
    "tril = torch.tril(torch.ones(T,T))\n",
    "weights = torch.zeros((T,T))\n",
    "\n",
    "# replace upper triangle -> -inf\n",
    "masked_weights = weights.masked_fill(tril == 0, float('-inf'))\n",
    "\n",
    "# on softmax, -inf -> 0, average of each row\n",
    "weights = torch.softmax(masked_weights, dim=1)\n",
    "\n",
    "xbow3 = weights @ x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "39967153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "401fd6ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "4f40569e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "4e2336de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "5538776e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2075, -0.6231],\n",
       "        [ 0.0937,  0.4413],\n",
       "        [ 0.1438, -0.0314],\n",
       "        [ 0.0358,  0.0413],\n",
       "        [ 0.1443,  0.1019],\n",
       "        [ 0.2577,  0.3573],\n",
       "        [ 0.1840,  0.0644],\n",
       "        [ 0.1088,  0.0769]])"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow3[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "e5acf1d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2075, -0.6231],\n",
       "        [ 0.0937,  0.4413],\n",
       "        [ 0.1438, -0.0314],\n",
       "        [ 0.0358,  0.0413],\n",
       "        [ 0.1443,  0.1019],\n",
       "        [ 0.2577,  0.3573],\n",
       "        [ 0.1840,  0.0644],\n",
       "        [ 0.1088,  0.0769]])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow2[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9e1535",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
